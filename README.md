# Code to Documentation Generator

This project analyzes Python code, builds a dependency graph between functions and components, retrieves relevant code snippets, and generates human-readable documentation using LLMs.

It combines **graph-based analysis** with **hybrid retrieval (BM25 + embeddings)** to fetch contextually relevant code and uses **Ollama-powered LLMs** to produce structured documentation.

---

## ğŸš€ Features

- Build a dependency graph of functions and components in a repo  
- Perform topological sorting & cycle detection for dependency resolution  
- Retrieve code context using a hybrid retriever (BM25 + dense embeddings)  
- Automatically generate documentation for queried code using an LLM  

---

## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ main.py                     
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ build_graph.py          
â”‚   â”œâ”€â”€ loader.py               # Loads docs, retrieves code with dependencies
â”‚   â”œâ”€â”€ parser.py               # Extracts functions/classes from source code
â”‚   â”œâ”€â”€ toposort.py             # Graph algorithms (DFS, Tarjan, topological sort)
â”œâ”€â”€ knowledge_base/             # Source repo/codebase to analyze
â”œâ”€â”€ output/
â”‚   â””â”€â”€ dependency_graph.json   # Auto-generated dependency graph
```

## âš™ï¸ Installation

### Clone the repo
```bash
git clone https://github.com/your-username/code-doc-gen.git
cd code-doc-gen
```

### Create a virtual environment
```bash
python -m venv venv
# On Linux/Mac:
source venv/bin/activate
# On Windows (Powershell):
venv\Scripts\Activate.ps1
```

### Install dependencies
```bash
pip install -r requirements.txt
```

**Core dependencies include:**
- `langchain`  
- `langchain-community`  
- `langchain-huggingface`  
- `langchain-ollama`  
- `faiss-cpu`  
- `rank-bm25`  
- `transformers`  

---

## Install and run Ollama

- Follow Ollama setup instructions: [Ollama.ai](https://ollama.ai)  
- Pull the required model (example uses `qwen3:0.6b`):
```bash
ollama pull qwen3:0.6b
```


## â–¶ï¸ Running the Project

1. Place your target source code inside the `knowledge_base/` folder.  
2. Run the main script:
   ```bash
   python main.py
3. On first run, it generates output/dependency_graph.json.

4. The retrievers fetch code relevant to the query.

5. The LLM outputs generated documentation in structured paragraphs.


## ğŸ” Example Usage

Inside `main.py`, set the query:
```python
query_code = "def backward():"
```

#### When executed, the pipeline:

* Finds the backward() function in the repo
* Expands its context by retrieving dependencies
* Sends it to the LLM (qwen3:0.6b)
* Produces documentation

## Example Output
```text
backward() is a function responsible for computing gradients in the training loop.
It depends on forward propagation results and updates model parameters accordingly.

In detail, backward() leverages loss computations and calls gradient update functions.
Its dependencies include optimizer utilities and helper functions defined in optimizer.py.
```